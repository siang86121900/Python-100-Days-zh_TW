## 深入淺出pandas-5

我們再來補充一些使用`DataFrame`做數據分析時會使用到的操作，這些操作不僅常見而且也非常重要。

### 計算同比環比

我們之前講過一個統計月度銷售額的例子，我們可以通過`groupby`方法做分組聚合，也可以通過`pivot_table`生成透視表，如下所示。

```python
sales_df = pd.read_excel('data/2020年銷售數據.xlsx')
sales_df['月份'] = sales_df.銷售日期.dt.month
sales_df['銷售額'] = sales_df.售價 * sales_df.銷售數量
result_df = sales_df.pivot_table(index='月份', values='銷售額', aggfunc='sum')
result_df.rename(columns={'銷售額': '本月銷售額'}, inplace=True)
result_df
```

輸出：

```
      本月銷售額
月份         
1       5409855
2       4608455
3       4164972
4       3996770
5       3239005
6       2817936
7       3501304
8       2948189
9       2632960
10      2375385
11      2385283
12      1691973
```

在得到月度銷售額之後，如果我們需要計算月環比，這里有兩種方案。第一種方案是我們可以使用`shift`方法對數據進行移動，將上一個月的數據與本月數據對齊，然後通過`(本月銷售額 - 上月銷售額) / 上月銷售額`來計算月環比，代碼如下所示。

```python
result_df['上月銷售額'] = result_df.本月銷售額.shift(1)
result_df
```

輸出：

```
      本月銷售額      上月銷售額
月份                    
1       5409855            NaN
2       4608455      5409855.0
3       4164972      4608455.0
4       3996770      4164972.0
5       3239005      3996770.0
6       2817936      3239005.0
7       3501304      2817936.0
8       2948189      3501304.0
9       2632960      2948189.0
10      2375385      2632960.0
11      2385283      2375385.0
12      1691973      2385283.0
```

在上面的例子中，`shift`方法的參數為`1`表示將數據向下移動一個單元，當然我們可以使用參數`-1`將數據向上移動一個單元。相信大家能夠想到，如果我們有更多年份的數據，我們可以將參數設置為`12`，這樣就可以計算今年的每個月與去年的每個月之間的同比。

```python
result_df['環比'] = (result_df.本月銷售額 - result_df.上月銷售額) / result_df.上月銷售額
result_df.style.format(
    formatter={'上月銷售額': '{:.0f}', '環比': '{:.2%}'},
    na_rep='--------'
)
```

輸出：

```
      本月銷售額      上月銷售額         環比
月份                    
1       5409855       --------     -------- 
2       4608455        5409855      -14.81%     
3       4164972        4608455       -9.62%
4       3996770        4164972       -4.04%
5       3239005        3996770      -18.96%
6       2817936        3239005      -13.00%
7       3501304        2817936       24.25%
8       2948189        3501304      -15.80%
9       2632960        2948189      -10.69%
10      2375385        2632960       -9.78%
11      2385283        2375385        0.42%
12      1691973        2385283      -29.07%
```

> **說明**：使用 JupyterLab 時，可以通過`DataFrame`對象的`style`屬性在網頁中對其進行渲染，上面的代碼通過`Styler`對象的`format`方法將環比格式化為百分比進行顯示，此外還指定了將空值替換為`--------`。

更為簡單的第二種方案是直接使用`pct_change`方法計算變化的百分比，我們先將之前的上月銷售額和環比列删除掉。

```python
result_df.drop(columns=['上月銷售額', '環比'], inplace=True)
```

接下來，我們使用`DataFrame`對象的`pct_change`方法完成環比的計算。值得一提的是，`pct_change`方法有一個名為`periods`的參數，它的默認值是`1`，計算相鄰兩項數據變化的百分比，這不就是我們想要的環比嗎？如果我們有很多年的數據，在計算時把這個參數的值修改為`12`，就可以得到相鄰兩年的月同比。

```python
result_df['環比'] = result_df.pct_change()
result_df
```

### 窗口計算

`DataFrame`對象的`rolling`方法允許我們將數據置於窗口中，然後用函數對窗口中的數據進行運算和處理。例如，我們獲取了某只股票近期的數據，想制作5日均線和10日均線，那麼就需要先設置窗口再進行運算。我們先用如下所示的代碼讀取2022年百度的股票數據，數據文件可以通過下面的鏈接來獲取。

```Python
baidu_df = pd.read_excel('data/2022年股票數據.xlsx', sheet_name='BIDU')
baidu_df.sort_index(inplace=True)
baidu_df
```

輸出：

<img src="res/baidu_stock.png" style="zoom:50%;">

上面的`DataFrame`有`Open`、`High`、`Low`、`Close`、`Volume`五個列，分別代表股票的開盤價、最高價、最低價、收盤價和成交量，接下來我們對百度的股票數據進行窗口計算。

```Python
baidu_df.rolling(5).mean()
```

輸出：

<img src="res/baidu_stock_ma5.png" style="zoom:50%;">

我們也可以在`Series`上使用`rolling`設置窗口並在窗口內完成運算，例如我們可以對上面的百度股票收盤價（`Close`列）計算5日均線和10日均線，並使用`merge`函數將其組裝到一個`DataFrame`對象中並繪制出雙均線圖，代碼如下所示。

```Python
close_ma5 = baidu_df.Close.rolling(5).mean()
close_ma10 = baidu_df.Close.rolling(10).mean()
result_df = pd.merge(close_ma5, close_ma10, left_index=True, right_index=True)
result_df.rename(columns={'Close_x': 'MA5', 'Close_y': 'MA10'}, inplace=True)
result_df.plot(kind='line', figsize=(10, 6))
plt.show()
```

輸出：

<img src="res/baidu_double_MA.png" style="zoom:50%;">

### 相關性判定

在統計學中，我們通常使用協方差（covariance）來衡量兩個隨機變量的聯合變化程度。如果變量 $X$ 的較大值主要與另一個變量 $Y$ 的較大值相對應，而兩者較小值也相對應，那麼兩個變量傾向於表現出相似的行為，協方差為正。如果一個變量的較大值主要對應於另一個變量的較小值，則兩個變量傾向於表現出相反的行為，協方差為負。簡單的說，協方差的正負號顯示着兩個變量的相關性。方差是協方差的一種特殊情況，即變量與自身的協方差。

$$
cov(X,Y) = E((X - \mu)(Y - \upsilon)) = E(X \cdot Y) - \mu\upsilon
$$

如果 $X$ 和 $Y$ 是統計獨立的，那麼二者的協方差為0，這是因為在 $X$ 和 $Y$ 獨立的情況下：

$$
E(X \cdot Y) = E(X) \cdot E(Y) = \mu\upsilon
$$

協方差的數值大小取決於變量的大小，通常是不容易解釋的，但是正態形式的協方差可以顯示兩變量線性關系的強弱。在統計學中，皮爾遜積矩相關系數就是正態形式的協方差，它用於度量兩個變量 $X$ 和 $Y$ 之間的相關程度（線性相關），其值介於`-1`到`1`之間。

$$
\frac {cov(X, Y)} {\sigma_{X}\sigma_{Y}}
$$

估算樣本的協方差和標準差，可以得到樣本皮爾遜系數，通常用希臘字母 $\rho$ 表示。

$$
\rho = \frac {\sum_{i=1}^{n}(X_i - \bar{X})(Y_i - \bar{Y})} {\sqrt{\sum_{i=1}^{n}(X_i - \bar{X})^2} \sqrt{\sum_{i=1}^{n}(Y_i - \bar{Y})^2}}
$$

我們用 $\rho$ 值判斷指標的相關性時遵循以下兩個步驟。

1. 判斷指標間是正相關、負相關，還是不相關。
    - 當 $ \rho \gt 0 $，認為變量之間是正相關，也就是兩者的趨勢一致。
    - 當 $ \rho \lt 0 $，認為變量之間是負相關，也就是兩者的趨勢相反。
    - 當 $ \rho \approx 0 $，認為變量之間是不相關的，但並不代表兩個指標是統計獨立的。
2. 判斷指標間的相關程度。
    - 當 $ \rho $ 的絕對值在 $ [0.6,1] $ 之間，認為變量之間是強相關的。
    - 當 $ \rho $ 的絕對值在 $ [0.1,0.6) $ 之間，認為變量之間是弱相關的。
    - 當 $ \rho $ 的絕對值在 $ [0,0.1) $ 之間，認為變量之間沒有相關性。

皮爾遜相關系數適用於：

  1. 兩個變量之間是線性關系，都是連續數據。
  2. 兩個變量的總體是正態分佈，或接近正態的單峰分佈。
  3. 兩個變量的觀測值是成對的，每對觀測值之間相互獨立。

這里，我們順便說一下，如果兩組變量並不是來自於正態總體的連續值，我們該如何判斷相關性呢？對於定序尺度（等級），我們可以使用斯皮爾曼秩相關系數，其計算公式如下所示：
$$
r_{s}=1-{\frac {6\sum d_{i}^{2}}{n(n^{2}-1)}}
$$
其中，$d_{i}=\operatorname {R} (X_{i})-\operatorname {R} (Y_{i})$，即每組觀測中兩個變量的等級差值，$n$為觀測樣本數。

對於定類尺度（類別），我們可以使用卡方檢驗的方式來判定其是否相關。其實很多時候，連續值也可以通過分箱的方式處理成離散的等級或類別，然後使用斯皮爾曼秩相關系數或卡方檢驗的方式來判定相關性。

`DataFrame`對象的`cov`方法和`corr`方法分別用於計算協方差和相關系數，`corr`方法有一個名為`method`的參數，其默認值是`pearson`，表示計算皮爾遜相關系數；除此之外，還可以指定`kendall`或`spearman`來計算肯德爾系數或斯皮爾曼秩相關系數。

我們從名為`boston_house_price.csv`的文件中獲取著名的波士頓房價數據集來創建一個`DataFrame`。

```python
boston_df = pd.read_csv('data/boston_house_price.csv')
boston_df
```

輸出：

<img src="/Users/Hao/Desktop/Python-Data-Analysis/res/boston_house_price.png" style="zoom:50%;">

> **說明**：上面代碼中使用了相對路徑來訪問 CSV 文件，也就是說 CSV 文件在當前工作路徑下名為`data`的文件夾中。如果需要上面例子中的 CSV 文件，可以通過下面的百度雲盤地址進行獲取。鏈接：<https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g?pwd=e7b4>，提取碼：e7b4。

可以看出，該數據集中包含了諸多影響房價的特徵，包括犯罪率、一氧化氮濃度、平均房間數、低收入人群佔比等，其中`PRICE`代表房價，具體情況如下所示。

<img src="res/boston_house_price_features.png" style="zoom:50%;">

接下來，我們將其中可以視為來自於正態總體的連續值，通過`corr`方法計算皮爾遜相關系數，看看哪些跟房價是正相關或負相關的關系，代碼如下所示。

```Python
boston_df[['NOX', 'RM', 'PTRATIO', 'LSTAT', 'PRICE']].corr()
```

輸出：

<img src="res/boston_person_correlation.png" style="zoom:50%;">

可以看出，平均房間數（`RM`）跟房價有較強的正相關性，而低收入人群佔比（`LSTAT`）跟房價之間存在明顯的負相關性。

斯皮爾曼秩相關系數對數據條件的要求沒有皮爾遜相關系數嚴格，只要兩個變量的觀測值是成對的等級數據，或者是由連續變量轉化成等級的數據，不論兩個變量的總體分佈形態、樣本容量的大小如何，都可以用斯皮爾曼等級相關系數來進行研究。我們可以通過下面的方式對部分特徵進行預處理，然後計算斯皮爾曼秩相關系數。

```Python
boston_df['CRIM'] = boston_df.CRIM.apply(lambda x: x // 5 if x < 25 else 5).map(int)
boston_df['ZN'] = pd.qcut(boston_df.ZN, q=[0, 0.75, 0.8, 0.85, 0.9, 0.95, 1], labels=np.arange(6))
boston_df['AGE'] = (boston_df.AGE // 20).map(int)
boston_df['DIS'] = (boston_df.DIS // 2.05).map(int)
boston_df['B'] = (boston_df.B // 66).map(int)
boston_df['PRICE'] = pd.qcut(boston_df.PRICE, q=[0, 0.15, 0.3, 0.5, 0.7, 0.85, 1], labels=np.arange(6))
boston_df[['CRIM', 'ZN', 'AGE', 'DIS', 'B', 'PRICE']].corr(method='spearman')
```

輸出：

<img src="res/boston_spearman_correlation.png" style="zoom:50%;">

可以看出，房價跟犯罪率（`CRIM`）和房齡（`AGE`）之間存在較為明顯的負相關關系，跟住房用地尺寸（`ZN`）存在微弱的正相關關系。相關性可以幫助我們在實際工作中找到業務抓手，即找到那些能夠影響或改變工作結果的相關因素。

