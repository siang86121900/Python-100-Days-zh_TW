## 深入淺出pandas-2

如果使用 pandas 做數據分析，那麼`DataFrame`一定是被使用得最多的類型，它可以用來保存和處理異質的二維數據。這里所謂的“異質”是指`DataFrame`中每個列的數據類型不需要相同，這也是它區別於 NumPy 二維數組的地方。`DataFrame`提供了極為豐富的屬性和方法，幫助我們實現對數據的重塑、清洗、預處理、透視、呈現等一系列操作。

### 創建DataFrame對象

#### 通過二維數組創建DataFrame對象

代碼：

```python
scores = np.random.randint(60, 101, (5, 3))
courses = ['語文', '數學', '英語']
stu_ids = np.arange(1001, 1006)
df1 = pd.DataFrame(data=scores, columns=courses, index=stu_ids)
df1
```

輸出：

```
		語文	數學	英語
1001    69    80	79
1002    71	  60	100
1003    94    81	93
1004    88	  88	67
1005    82	  66    60
```

#### 通過字典創建DataFrame對象

代碼：

```python
scores = {
    '語文': [62, 72, 93, 88, 93],
    '數學': [95, 65, 86, 66, 87],
    '英語': [66, 75, 82, 69, 82],
}
stu_ids = np.arange(1001, 1006)
df2 = pd.DataFrame(data=scores, index=stu_ids)
df2
```

輸出：

```
        語文  數學  英語
1001    62    95    66
1002    72    65    75
1003    93    86    82
1004    88    66    69
1005    93    87    82
```

#### 讀取CSV文件創建DataFrame對象

可以通過`pandas` 模塊的`read_csv`函數來讀取 CSV 文件，`read_csv`函數的參數非常多，下面介紹幾個比較重要的參數。

- `sep` / `delimiter`：分隔符，默認是`,`。
- `header`：表頭（列索引）的位置，默認值是`infer`，用第一行的內容作為表頭（列索引）。
- `index_col`：用作行索引（標簽）的列。
- `usecols`：需要加載的列，可以使用序號或者列名。
- `true_values` / `false_values`：哪些值被視為佈爾值`True` / `False`。
- `skiprows`：通過行號、索引或函數指定需要跳過的行。
- `skipfooter`：要跳過的末尾行數。
- `nrows`：需要讀取的行數。
- `na_values`：哪些值被視為空值。
- `iterator`：設置為`True`，函數返回迭代器對象。
- `chunksize`：配合上面的參數，設置每次迭代獲取的數據體量。

代碼：

```python
df3 = pd.read_csv('data/2018年北京積分落戶數據.csv', index_col='id')
df3
```

> **提示**：上面代碼中的CSV文件是用相對路徑進行獲取的，也就是說當前工作路徑下有名為`data`的文件夾，而“2018年北京積分落戶數據.csv”就在這個文件夾下。如果使用Windows系統，在寫路徑分隔符時也建議使用`/`而不是`\`，如果想使用`\`，建議在字符串前面添加一個`r`，使用原始字符串來避開轉義字符，例如`r'c:\new\data\2018年北京積分落戶數據.csv'`。

輸出：

```
      name   birthday      company          score
id                                             
1     楊xx   1972-12       北京利德華福xxxx  122.59
2     紀xx   1974-12       北京航天數據xxxx  121.25
3     王x    1974-05       品牌聯盟(北京)xx  118.96
4     楊x    1975-07       中科專利商標xxxx  118.21
5     張xx   1974-11       北京阿里巴巴xxxx  117.79
...   ...      ...                  ...     ...
6015  孫xx   1978-08       華為海洋網絡xxxx   90.75
6016  劉xx   1976-11       福斯（上海）xxxx   90.75
6017  週x    1977-10       贏創德固賽xxxxxx   90.75
6018  趙x    1979-07       澳科利耳醫療xxxx   90.75
6019  賀x    1981-06       北京寶潔技術xxxx   90.75

[6019 rows x 4 columns]
```

> **說明**： 上面輸出的內容隱去了姓名（name）和公司名稱（company）字段中的部分信息。如果需要上面例子中的 CSV 文件，可以通過百度雲盤獲取，鏈接：<https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g>，提取碼：e7b4。

#### 讀取Excel工作表創建DataFrame對象

可以通過`pandas` 模塊的`read_excel`函數來讀取 Excel 文件，該函數與上面的`read_csv`非常類似，多了一個`sheet_name`參數來指定數據表的名稱，但是不同於 CSV 文件，沒有`sep`或`delimiter`這樣的參數。假設有名為“2022年股票數據.xlsx”的 Excel 文件，里面有用股票代碼命名的五個表單，分別是阿里巴巴（BABA）、百度（BIDU）、京東（JD）、亞馬遜（AMZN）、甲骨文（ORCL）這五個公司2022年的股票數據，如果想加載亞馬遜的股票數據，代碼如下所示。

代碼：

```python
df4 = pd.read_excel('data/2022年股票數據.xlsx', sheet_name='AMZN', index_col='Date')
df4
```

> **說明**：上面例子中的 CSV 文件可以通過百度雲盤獲取，鏈接：<https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g>，提取碼：e7b4。

輸出：

```
               Open     High       Low    Close    Volume
Date                                                     
2022-12-30   83.120   84.050   82.4700   84.000  62401194
2022-12-29   82.870   84.550   82.5500   84.180  54995895
2022-12-28   82.800   83.480   81.6900   81.820  58228575
2022-12-27   84.970   85.350   83.0000   83.040  57284035
2022-12-23   83.250   85.780   82.9344   85.250  57433655
...             ...      ...       ...      ...       ...
2022-01-07  163.839  165.243  162.0310  162.554  46605900
2022-01-06  163.450  164.800  161.9370  163.254  51957780
2022-01-05  166.883  167.126  164.3570  164.357  64302720
2022-01-04  170.438  171.400  166.3490  167.522  70725160
2022-01-03  167.550  170.704  166.1600  170.404  63869140

[251 rows x 5 columns]
```

#### 讀取關系數據庫二維表創建DataFrame對象

`pandas`模塊的`read_sql`函數可以通過 SQL 語句從數據庫中讀取數據創建`DataFrame`對象，該函數的第二個參數代表了需要連接的數據庫。對於 MySQL 數據庫，我們可以通過`pymysql`或`mysqlclient`來創建數據庫連接（需要提前安裝好三方庫），得到一個`Connection` 對象，而這個對象就是`read_sql`函數需要的第二個參數，代碼如下所示。

代碼：

```python
import pymysql

# 創建一個MySQL數據庫的連接對象
conn = pymysql.connect(
    host='101.42.16.8', port=3306,
    user='guest', password='Guest.618',
    database='hrs', charset='utf8mb4'
)
# 通過SQL從數據庫二維表讀取數據創建DataFrame
df5 = pd.read_sql('select * from tb_emp', conn, index_col='eno')
df5
```

> **提示**：執行上面的代碼需要先安裝`pymysql`庫，如果尚未安裝，可以先在單元格中先執行魔法指令`%pip install pymysql`，然後再運行上面的代碼。上面的代碼連接的是我部署在騰訊雲上的 MySQL 數據庫，公網 IP 地址：`101.42.16.8`，用戶名：`guest`，密碼：`Guest.618`，數據庫：`hrs`，字符集：`utf8mb4`，大家可以使用這個數據庫，但是不要進行惡意的訪問。`hrs`數據庫一共有三張表，分別是：`tb_dept`（部門表）、`tb_emp`（員工表）、`tb_emp2`（員工表2）。

輸出：

```
       ename   job     mgr     sal    comm    dno
eno                                        
1359   胡一刀   銷售員  3344.0  1800   200.0   30
2056    喬峰   分析師   7800.0  5000  1500.0   20
3088   李莫愁   設計師  2056.0  3500   800.0   20
3211   張無忌   程序員  2056.0  3200     NaN   20
3233   丘處機   程序員  2056.0  3400     NaN   20
3244   歐陽鋒   程序員  3088.0  3200     NaN   20
3251   張翠山   程序員  2056.0  4000     NaN   20
3344    黃蓉  銷售主管  7800.0  3000   800.0   30
3577    楊過    會計    5566.0  2200     NaN   10
3588   朱九真    會計   5566.0  2500     NaN   10
4466   苗人鳳   銷售員  3344.0  2500     NaN   30
5234    郭靖    出納    5566.0  2000     NaN   10
5566   宋遠橋   會計師  7800.0  4000  1000.0   10
7800   張三豐    總裁     NaN   9000  1200.0   20
```

執行上面的代碼會出現一個警告，因為 pandas 庫希望我們使用`SQLAlchemy`三方庫接入數據庫，具體內容是：“UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.”。如果不想看到這個警告，我們可以試一試下面的解決方案。

首先，安裝三方庫`SQLAlchemy`，在 Jupyter 中可以使用`%pip`魔法指令。

```python
%pip install sqlalchemy
```

通過`SQLAlchemy`的`create_engine`函數創建`Engine`對象作為`read_sql`函數的第二個參數，此時`read_sql`函數的第一個參數可以是 SQL 語句，也可以是二維表的表名。

```python
from sqlalchemy import create_engine

# 通過指定的URL（統一資源定位符）訪問數據庫
engine = create_engine('mysql+pymysql://guest:Guest.618@101.42.16.8:3306/hrs')
# 直接通過表名加載整張表的數據
df5 = pd.read_sql('tb_emp', engine, index_col='eno')
df5
```

> **說明**：如果通過表名加載二維表數據，也可以將上面的函數換成`read_sql_table`。

我們再來加載部門表的數據創建`DataFrame`對象。

```python
df6 = pd.read_sql('select dno, dname, dloc from tb_dept', engine, index_col='dno')
df6
```

> **說明**：如果通過 SQL 查詢獲取數據，也可以將上面的函數換成`read_sql_query`。

輸出：

```
      dname   dloc
dno           
10    會計部   北京
20    研發部   成都
30    銷售部   重慶
40    運維部   深圳
```

在完成數據加載後，如果希望釋放數據庫連接，可以使用下面的代碼。

```python
engine.connect().close()
```

### 基本屬性和方法

在開始講解`DataFrame`的屬性和方法前，我們先從之前提到的`hrs`數據庫中讀取三張表的數據，創建出三個`DataFrame`對象，完整的代碼如下所示。

```python
from sqlalchemy import create_engine

engine = create_engine('mysql+pymysql://guest:Guest.618@101.42.16.8:3306/hrs')
dept_df = pd.read_sql_table('tb_dept', engine, index_col='dno')
emp_df = pd.read_sql_table('tb_emp', engine, index_col='eno')
emp2_df = pd.read_sql_table('tb_emp2', engine, index_col='eno')
```

得到的三個`DataFrame`對象如下所示。

部門表（`dept_df`），其中`dno`是部門的編號，`dname`和`dloc`分別是部門的名稱和所在地。

```
    dname  dloc
dno
10	會計部	北京
20	研發部	成都
30	銷售部	重慶
40	運維部	深圳
```

員工表（`emp_df`），其中`eno`是員工編號，`ename`、`job`、`mgr`、`sal`、`comm`和`dno`分別代表員工的姓名、職位、主管編號、月薪、補貼和部門編號。

```
        ename    job        mgr      sal     comm    dno
eno
1359	胡一刀    銷售員	   3344.0	1800	200.0	30
2056	喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3088	李莫愁	   設計師	   2056.0	3500	800.0	20
3211	張無忌	   程序員	   2056.0	3200	NaN     20
3233	丘處機	   程序員	   2056.0	3400	NaN	    20
3244	歐陽鋒	   程序員	   3088.0	3200	NaN     20
3251	張翠山	   程序員	   2056.0	4000	NaN	    20
3344	黃蓉	    銷售主管   7800.0	3000	800.0	30
3577	楊過	    會計	     5566.0	  2200	  NaN	  10
3588	朱九真	   會計	    5566.0	 2500	 NaN	 10
4466	苗人鳳	   銷售員	   3344.0	2500	NaN	    30
5234	郭靖	    出納	     5566.0	  2000	  NaN	  10
5566	宋遠橋	   會計師	   7800.0	4000	1000.0	10
7800	張三豐	   總裁	    NaN      9000	 1200.0	 20
```

> **說明**：在數據庫中`mgr`和`comm`兩個列的數據類型是`int`，但是因為有缺失值（空值），讀取到`DataFrame`之後，列的數據類型變成了`float`，因為我們通常會用`float`類型的`NaN`來表示空值。

員工表（`emp2_df`），跟上面的員工表結構相同，但是保存了不同的員工數據。

```
       ename    job      mgr      sal    comm    dno
eno                                      
9500   張三豐   總裁      NaN      50000  8000    20
9600   王大錘   程序員    9800.0   8000   600     20
9700   張三豐   總裁      NaN      60000  6000    20
9800   駱昊     架構師    7800.0   30000  5000    20
9900   陳小刀   分析師    9800.0   10000  1200    20
```

`DataFrame`對象的屬性如下表所示。

| 屬性名         | 說明                                |
| -------------- | ----------------------------------- |
| `at` / `iat`   | 通過標簽獲取`DataFrame`中的單個值。 |
| `columns`      | `DataFrame`對象列的索引             |
| `dtypes`       | `DataFrame`對象每一列的數據類型     |
| `empty`        | `DataFrame`對象是否為空             |
| `loc` / `iloc` | 通過標簽獲取`DataFrame`中的一組值。 |
| `ndim`         | `DataFrame`對象的維度               |
| `shape`        | `DataFrame`對象的形狀（行數和列數） |
| `size`         | `DataFrame`對象中元素的個數         |
| `values`       | `DataFrame`對象的數據對應的二維數組 |

關於`DataFrame`的方法，首先需要了解的是`info()`方法，它可以幫助我們了解`DataFrame`的相關信息，如下所示。

代碼：

```python
emp_df.info()
```

輸出：

```
<class 'pandas.core.frame.DataFrame'>
Int64Index: 14 entries, 1359 to 7800
Data columns (total 6 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   ename   14 non-null     object 
 1   job     14 non-null     object 
 2   mgr     13 non-null     float64
 3   sal     14 non-null     int64  
 4   comm    6 non-null      float64
 5   dno     14 non-null     int64  
dtypes: float64(2), int64(2), object(2)
memory usage: 1.3+ KB
```

如果需要查看`DataFrame`的頭部或尾部的數據，可以使用`head()`或`tail()`方法，這兩個方法的默認參數是`5`，表示獲取`DataFrame`最前面5行或最後面5行的數據，如下所示。

```python
emp_df.head()
```

輸出：

```
        ename    job    mgr    sal    comm  dno
eno						
1359	胡一刀   銷售員	3344   1800  200   30
2056	喬峰	   分析師	 7800   5000  1500	20
3088	李莫愁	  設計師	2056   3500  800   20
3211	張無忌	  程序員	2056   3200  NaN   20
3233	丘處機	  程序員	2056   3400	 NaN   20
```

### 操作數據

#### 索引和切片

如果要獲取`DataFrame`的某一列，例如取出上面`emp_df`的`ename`列，可以使用下面的兩種方式。

```python
emp_df.ename
```

或者

```python
emp_df['ename']
```

執行上面的代碼可以發現，我們獲得的是一個`Series`對象。事實上，`DataFrame`對象就是將多個`Series`對象組合到一起的結果。

如果要獲取`DataFrame`的某一行，可以使用整數索引或我們設置的索引，例如取出員工編號為`2056`的員工數據，代碼如下所示。

```python
emp_df.iloc[1]
```

或者

```python
emp_df.loc[2056]
```

通過執行上面的代碼我們發現，單獨取`DataFrame` 的某一行或某一列得到的都是`Series`對象。我們當然也可以通過花式索引來獲取多個行或多個列的數據，花式索引的結果仍然是一個`DataFrame`對象。

獲取多個列：

```python
emp_df[['ename', 'job']]
```

獲取多個行：

```python
emp_df.loc[[2056, 7800, 3344]]
```

如果要獲取或修改`DataFrame` 對象某個單元格的數據，需要同時指定行和列的索引，例如要獲取員工編號為`2056`的員工的職位信息，代碼如下所示。

```python
emp_df['job'][2056]
```

或者

```python
emp_df.loc[2056]['job']
```

或者

```python
emp_df.loc[2056, 'job']
```

我們推薦大家使用第三種做法，因為它只做了一次索引運算。如果要將該員工的職位修改為“架構師”，可以使用下面的代碼。

```python
emp_df.loc[2056, 'job'] = '架構師'
```

當然，我們也可以通過切片操作來獲取多行多列，相信大家一定已經想到了這一點。

```python
emp_df.loc[2056:3344]
```

輸出：

```
        ename    job        mgr      sal     comm    dno
eno
2056	喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3088	李莫愁	   設計師	   2056.0	3500	800.0	20
3211	張無忌	   程序員	   2056.0	3200	NaN     20
3233	丘處機	   程序員	   2056.0	3400	NaN	    20
3244	歐陽鋒	   程序員	   3088.0	3200	NaN     20
3251	張翠山	   程序員	   2056.0	4000	NaN	    20
3344	黃蓉	    銷售主管   7800.0	3000	800.0	30
```

#### 數據篩選

上面我們提到了花式索引，相信大家已經聯想到了佈爾索引。跟`ndarray`和`Series`一樣，我們可以通過佈爾索引對`DataFrame`對象進行數據篩選，例如我們要從`emp_df`中篩選出月薪超過`3500`的員工，代碼如下所示。

```python
emp_df[emp_df.sal > 3500]
```

輸出：

```
        ename    job        mgr      sal     comm    dno
eno
2056	喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3251	張翠山	   程序員	   2056.0	4000	NaN	    20
5566	宋遠橋	   會計師	   7800.0	4000	1000.0	10
7800	張三豐	   總裁	    NaN      9000	 1200.0	 20
```

當然，我們也可以組合多個條件來進行數據篩選，例如從`emp_df`中篩選出月薪超過`3500`且部門編號為`20`的員工，代碼如下所示。

```python
emp_df[(emp_df.sal > 3500) & (emp_df.dno == 20)]
```

輸出：

```
        ename    job        mgr      sal     comm    dno
eno
2056	喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3251	張翠山	   程序員	   2056.0	4000	NaN	    20
7800	張三豐	   總裁	    NaN      9000	 1200.0	 20
```

除了使用佈爾索引，`DataFrame`對象的`query`方法也可以實現數據篩選，`query`方法的參數是一個字符串，它代表了篩選數據使用的表達式，而且更符合 Python 程序員的使用習慣。下面我們使用`query`方法將上面的效果重新實現一遍，代碼如下所示。

```python
emp_df.query('sal > 3500 and dno == 20')
```
